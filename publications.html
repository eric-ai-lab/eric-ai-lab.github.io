<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">

        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>UC ERIC Lab</title>


        <link rel="stylesheet" href="static/css/bootstrap.min.css">
        <link rel="stylesheet" href="static/css/fonts.css">
        <link rel="stylesheet" href="static/css/custom.css">
    </head>

    <body>
        <nav class="navbar navbar-expand-lg navbar-dark navbar-custom fixed-top">
            <div class="container">
                <a class="navbar-brand" href="index.html"><b>UC ERIC Lab</b></a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#content" aria-controls="navbarsExample07" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <div class="collapse navbar-collapse" id="content">
                    <ul class="navbar-nav ml-auto">
                        <li class="nav-item">
			    	<a class="nav-link" href="index.html"><b>Home</b></a>
                        </li>
                        <li class="nav-item">
				<a class="nav-link" href="people.html">People</a>
                        </li>
                        <li class="nav-item active">
				<a class="nav-link" href="publications.html">Publications</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="https://github.com/eric-ai-lab">Github</a>
                        </li>
                        <li class="nav-item">
				<a class="nav-link" href="sponsors.html">Sponsors</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="https://eric-xw.github.io/hiring.html" target="_blank">Join Us</a>
                        </li>
                        <li class="nav-item">
				<a class="nav-link" href="contact.html">Contact</a>
                        </li>
                        <!-- <li class="nav-item"> 
                            <a class="nav-link" href="{{ url_for('ACLtool') }}">ACL Tool</a>
                        </li> -->
                    </ul>
                </div>
            </div>
        </nav>

        <br/>
        <br/>

        
        <div class="container" align="justify">
        <div class="col-lg-12 col-md-12 col-sm-12 col-xs-12 thumb">
            <h3>All Publications (from newest to oldest)</h3>

                <!-- copy paste here to add more
                    <li class="li-paper">
                    <span class="title">Placeholder for paper titles</span>
                    <span>Placeholder for Authors</span>
                    <span>
                        <b>Placeholder for Conference Name, Year</b>
                    </span>
                    <span>
                    </span>
                    </li> 
                -->
                <h4>2025</h4>
                <p><ul class="ul-paper">
                    <li class="li-paper">
                        <span class="title">
                            SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning</span>
                        <span>Kaiwen Zhou, Yue Fan, Kian Ahrabian, Dan Roth, Xin Eric Wang</span>
                        <span>
                            <b>EMNLP 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            Hidden in Plain Sight: Probing Implicit Reasoning in Multimodal Language Models</span>
                        <span>Qianqi Yan, Kaiwen Zhou, Shan Jiang, Yue Fan, Xin Eric Wang</span>
                        <span>
                            <b>EMNLP 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration</span>
                        <span>Jiuzhou Han, Yue Fan, Lei Ding, Weixi Feng, Linjie Li, Zhengyuan Yang, Kevin Lin, Jianfeng Wang, Lijuan Wang, Xin Eric Wang</span>
                        <span>
                            <b>EMNLP 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents</span>
                        <span>Jiuzhou Han*, Saaket Agashe*, Shuyu Gan, Ying Chen, Yue Fan, Xin Eric Wang</span>
                        <span>
                            <b>COLM 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            VLM4D: Towards Spatiotemporal Awareness in Vision Language Models</span>
                        <span>Weixi Feng*, Yue Fan*, Jiuzhou Han, Kaizhi Zheng, Kaiwen Zhou, Shan Jiang, Yang Zhao, Yachuan Li, Xin Eric Wang</span>
                        <span>
                            <b>ICCV 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for Multimodal Reasoning Models</span>
                        <span>Qianqi Yan, Yue Fan, Hongquan Li, Shan Jiang, Yang Zhao, Xinze Guan, Ching-Chen Kuo, Xin Eric Wang</span>
                        <span>
                            <b>Findings of ACL 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA</span>
                        <span>Qianqi Yan, Xuehai He, Xiang Yue, Xin Eric Wang</span>
                        <span>
                            <b>Findings of ACL 2025</b><br>
                            <em>NeurIPS 2024 Workshop on GenAI for Health</em>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            Agent S: An Open Agentic Framework that Uses Computers Like a Human</span>
                        <span>Saaket Agashe*, Jiuzhou Han*, Shuyu Gan, Jiachen Yang, Ang Li, Xin Eric Wang</span>
                        <span>
                            <b>ICLR 2025</b><br>
                            <font color="red">Best Paper Award</font> <em>(ICLR 2025 Agentic AI for Science Workshop)</em>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            Multimodal Situational Safety</span>
                        <span>Kaiwen Zhou*, Chengzhi Liu*, Xuandong Zhao, Anderson Compalas, Dawn Song, Xin Eric Wang</span>
                        <span>
                            <b>ICLR 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos</span>
                        <span>Xuehai He, Weixi Feng, Kaizhi Zheng, Yujie Lu, Wanrong Zhu, Jiachen Li, Yue Fan, Jianfeng Wang, Linjie Li, Zhengyuan Yang, Kevin Lin, William Yang Wang, Lijuan Wang, Xin Eric Wang</span>
                        <span>
                            <b>ICLR 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing</span>
                        <span>Kaizhi Zheng, Xiaotong Chen, Xuehai He, Jing Gu, Linjie Li, Zhengyuan Yang, Kevin Lin, Jianfeng Wang, Lijuan Wang, Xin Eric Wang</span>
                        <span>
                            <b>ICLR 2025</b>
                        </span>
                    </li>
                    <li class="li-paper">
                        <span class="title">
                            LLM-Coordination: Evaluating and Analyzing Multi-Agent Coordination Abilities in Large Language Models</span>
                        <span>Saaket Agashe, Yue Fan, Anthony Reyna, Xin Eric Wang</span>
                        <span>
                            <b>Findings of NAACL 2025</b>
                        </span>
                    </li>
        <h4>2024</h4>
        <p><ul class="ul-paper">
            <li class="li-paper">
                <span class="title">
                    Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding</span>
                <span>Yue Fan, Lei Ding, Ching-Chen Kuo, Shan Jiang, Yang Zhao, Xinze Guan, Jie Yang, Yi Zhang, Xin Eric Wang</span>
                <span>
                    <b>EMNLP 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting</span>
                <span>Kevin Bowden, Yue Fan, Winsom Chen, Wen Cui, Davan Harrison, Xin Eric Wang, Marilyn Walker</span>
                <span>
                    <b>Findings of EMNLP 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    Multimodal Procedural Planning via Dual Text-Image Prompting</span>
                <span>Yujie Lu, Pan Li, Zhiyu Chen, Wanrong Zhu, Xin Eric Wang, William Yang Wang</span>
                <span>
                    <b>Findings of EMNLP 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    FlexEControl: Flexible and Efficient Multimodal Control for Text-to-Image Generation</span>
                <span>Xuehai He, Jian Zheng, Jacob Zhiyuan Fang, Robinson Piramuthu, Mohit Bansal, Vicente Ordonez, Gunnar A Sigurdsson, Nanyun Peng, Xin Eric Wang</span>
                <span>
                    <b>Transactions on Machine Learning Research (TMLR) 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    Discfusion: Discriminative Diffusion Models as Few-shot Vision and Language Learners</span>
                <span>Xuehai He, Weixi Feng, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna Narayana, Sugato Basu, William Yang Wang, Xin Eric Wang</span>
                <span>
                    <b>Transactions on Machine Learning Research (TMLR) 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing</span>
                <span>Jing Gu, Yilin Wang, Nanxuan Zhao, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, Xin Eric Wang</span>
                <span>
                    <b>ECCV 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models</span>
                <span>Gengze Zhou, Yicong Hong, Zun Wang, Xin Eric Wang, Qi Wu</span>
                <span>
                    <b>ECCV 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    Muffin or Chihuahua? Challenging Large Vision-Language Models with Multipanel VQA</span>
                <span>Yue Fan, Jing Gu, Kaiwen Zhou, Qianqi Yan, Shan Jiang, Ching-Chen Kuo, Xinze Guan, Xin Eric Wang</span>
                <span>
                    <b>ACL 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models</span>
                <span>Kaiwen Zhou, Kwonjoon Lee, Teruhisa Mitsu, Xin Eric Wang</span>
                <span>
                    <b>ACL 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    Navigation as Attackers Wish? Towards Building Byzantine-Robust Embodied Agents under Federated Learning</span>
                <span>Yunchao Zhang, Zonglin Di, Kaiwen Zhou, Cihang Xie, Xin Eric Wang</span>
                <span>
                    <b>NAACL 2024</b>
                </span>
            </li>
            <li class="li-paper">
                <span class="title">
                    ComCLIP: Training-Free Compositional Image and Text Matching</span>
                <span>Kenan Jiang*, Xuehai He*, Ruize Xu, Xin Eric Wang</span>
                <span>
                    <b>NAACL 2024</b>
                </span>
            </li>

	    <h4>2023</h4>
		<p><ul class="ul-paper">
        <li class="li-paper">
                <span class="title">
                    Photoswap: Personalized Subject Swapping in Images</span>
                <span>Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, Qing Liu, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, Xin Eric Wang</span>
                <span>
                        <b>NeurIPS 2023</b>
                </span>
                <span>
                </span>
        </li>
        <li class="li-paper">
                <span class="title">LayoutGPT: Compositional Visual Planning and Generation with Large Language Models</span>
                <span>Weixi Feng*, Wanrong Zhu*, Tsu-jui Fu, Varun Jampani, Arjun Akula, Xuehai He, Sugato Basu, Xin Eric Wang, William Yang Wang</span>
                <span>
                        <b>NeurIPS 2023</b>
                </span>
                <span>
                </span>
        </li>
        <li class="li-paper">
                <span class="title">LLMScore: Unveiling the Power of Large Language Models in Text-to-Image Synthesis Evaluation</span>
                <span>Yujie Lu, Xianjun Yang, Xiujun Li, Xin Eric Wang, William Yang Wang</span>
                <span>
                        <b>NeurIPS 2023</b>
                </span>
                <span>
                </span>
        </li>
        <li class="li-paper">
                <span class="title">R2H: Building Multimodal Navigation Helpers that Respond to Help Requests</span>
                <span>Yue Fan, Jing Gu, Kaizhi Zheng, Xin Eric Wang</span>
                <span>
                        <b>EMNLP 2023</b>
                </span>
                <span>
                </span>
        </li>      
        <li class="li-paper">
            <span class="title">Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation</span>
            <span>Wanrong Zhu, Xinyi Wang, Yujie Lu, Tsu-Jui Fu, Xin Eric Wang, Miguel Eckstein, William Yang Wang</span>
            <span>
                    <b>EMNLP 2023</b>
            </span>
            <span>
            </span>
        </li>
        <li class="li-paper">
            <span class="title">Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment</span>
            <span>Zhen Zhang, Jialu Wang, Xin Eric Wang</span>
            <span>
                    <b>Findings of EMNLP 2023</b>
            </span>
            <span>
            </span>
        </li> 
        <li class="li-paper">
            <span class="title">
                Aerial Vision-and-Dialog Navigation</span>
            <span>Yue Fan, Winson Chen, Tongzhou Jiang, Chun Zhou, Yi Zhang, Xin Eric Wang</span>
            <span>
                    <b>Findings of ACL 2023</b>
            </span>
            <span>
            </span>
        </li>
        <li class="li-paper">
                <span class="title">
                    T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image Generation</span>
                <span>Jialu Wang, Xinyue Gabby Liu, Zonglin Di, Yang Liu, Xin Eric Wang</span>
                <span>
                        <b>Findings of ACL 2023</b>
                </span>
                <span>
                </span>
        </li>

			<li class="li-paper">
                                <span class="title">ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation</span>
                                <span>Kaiwen Zhou, Kaizhi Zheng, Connor Pryor, Yilin Shen, Hongxia Jin, Lise Getoor, Xin Eric Wang</span>
                                <span>
                                        <b>ICML 2023</b>
                                </span>
                                <span>
                                </span>
                        </li>
			<li class="li-paper"> 
				<span class="title">Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis</span> 
				<span>Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna Narayana, Sugato Basu, Xin Eric Wang, William Yang Wang</span> 
				<span> 
					<b>ICLR 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>
			<li class="li-paper"> 
				<span class="title">Neuro-Symbolic Procedural Planning with Commonsense Prompting</span> 
				<span>Yujie Lu, Weixi Feng, Wanrong Zhu, Wenda Xu, Xin Eric Wang, Miguel Eckstein, William Yang Wang</span> 
				<span> 
					<b>ICLR 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>
			<li class="li-paper"> 
				<span class="title">Multimodal Graph Transformer for Multimodal Question Answering</span> 
				<span>Xuehai He, Xin Eric Wang</span> 
				<span> 
					<b>EACL 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>
			<li class="li-paper"> 
				<span class="title">Visualize Before You Write: Imagination-Guided Open-Ended Text Generation</span> 
				<span>Wanrong Zhu, An Yan, Yujie Lu, Wenda Xu, Xin Eric Wang, Miguel Eckstein, William Yang Wang</span> 
				<span> 
					<b>EACL 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>
			<li class="li-paper"> 
				<span class="title">ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation</span> 
				<span>Wanrong Zhu, Xin Eric Wang, An Yan, Miguel Eckstein, William Yang Wang</span> 
				<span> 
					<b>EACL 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>

			<li class="li-paper">
			    <span class="title">Parameter-efficient Model Adaptation for Vision Transformers</span>
			    <span>Xuehai He, Chunyuan Li, Pengchuan Zhang, Jianwei Yang, Xin Eric Wang</span>
			    <span>
			        <b>AAAI 2023</b>
			    </span>
			    <span>
			    </span>
			</li> 
            <li class="li-paper"> 
				<span class="title">Athena 3.0: Personalized Multimodal Chatbot with Neuro-symbolic Dialogue Generators</span> 
				<span>Yue Fan, Kevin K. Bowden, Wen Cui, Winson Chen, Vrindavan Harrison, Angela Ramirez, Saaket Agashe, Xinyue Gabby Liu, Neha Pullabhotla, Nan Qiang, Jeshwanth Bheemanpally, Sugam Garg, Marilyn Walker, Xin Eric Wang</span> 
				<span> 
					<b>Alexa Prize SocialBot Grand Challenge 5 Proceedings 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>
			<li class="li-paper"> 
				<span class="title">Sage: A Multimodal Knowledge Graph-based Conversational Agent for Complex Task Guidance</span> 
				<span>Kaizhi Zheng, Jeshwanth Bheemanpally, Bhrigu Garg, Seongsil Heo, Dhananjay Sonawane, Winson Chen, Shree Vignesh S, Xin Eric Wang</span> 
				<span> 
					<b>Alexa Prize TaskBot Challenge 2 Proceedings 2023</b> 
				</span> 
				<span> 
				</span> 
			</li>

			<li class="li-paper">
			    <span class="title">SlugJARVIS: Multimodal Commonsense Knowledge-based Embodied AI for SimBot Challenge</span>
			    <span>Jing Gu, Kaizhi Zheng, Kaiwen Zhou, Yue Fan, Xuehai He, Jialu Wang, Zonglin Di, Xin Eric Wang</span>
			    <span>
			        <b>Alexa Prize SimBot Challenge Proceedings 2023</b>
			    </span>
			    <span>
			    </span>
			</li> 

		
	    <h4>2022</h4>
            


                <li class="li-paper">
                    <span class="title">CPL: Counterfactual Prompt Learning for Vision and Language Models</span>
                    <span>Xuehai He, Diji Yang, Weixi Feng, Tsu-Jui Fu, Arjun Akula, Varun Jampani, Pradyumna Narayana, Sugato Basu, William Yang Wang, Xin Eric Wang</span>
                    <span>
                        <b>EMNLP 2022</b>
                    </span>
                    <span>
                    </span>
                    </li> 
                <li class="li-paper">
                    <span class="title">VLMbench: A Compositional Benchmark for Vision-and-Language Manipulation</span>
                    <span>Kaizhi Zheng, Xiaotong Chen, Odest Chadwicke Jenkins, Xin Eric Wang</span>
                    <span>
                        <b>NeurlPS 2022</b>
                    </span>
                </li> 

		<li class="li-paper"> 
		    <span class="title">FedVLN: Privacy-preserving Federated Vision-and-Language Navigation</span>
		    <span>Kaiwen Zhou, Xin Eric Wang</span>
		    <span>
			<b>ECCV 2022</b> 
		    </span> 
		</li> 
		<li class="li-paper"> 
		    <span class="title">Language-Driven Artistic Style Transfer</span>
		    <span>Tsu-Jui Fu, Xin Eric Wang, William Yang Wang</span>
		    <span> 
			<b>ECCV 2022</b>
		    </span> 
		</li>
                <li class="li-paper">
                    <span class="title">Understanding Instance-Level Impact of Fairness Constraints                            </span>
                    <span>Jialu Wang, Xin Eric Wang, Yang Liu                            </span>
                    <span>
                        <b>ICML 2022</b>
                    </span>
                    <span>
                    </span>
                </li> 
                <li class="li-paper">
                    <span class="title">Imagination-Augmented Natural Language Understanding</span>
                    <span>Yujie Lu, Wanrong Zhu, Xin Eric Wang, Miguel Eckstein, William Yang Wang</span>
                    <span>
                        <b>NAACL 2022</b>
                    </span>
                    <span>
                    </span>
                </li> 
                <li class="li-paper">
                    <span class="title">Diagnosing Vision-and-Language Navigation: What Really Matters</span>
                    <span>Wanrong Zhu, Yuankai Qi, Pradyumna Narayana, Kazoo Sone, Sugato Basu, Xin Eric Wang, Qi Wu, Miguel Eckstein, William Yang Wang</span>
                    <span>
                        <b>NAACL 2022</b>
                    </span>
                    <span>
                    </span>
                </li> 
                <li class="li-paper">
                    <span class="title">Compositional Temporal Grounding with Structured Variational Cross-Graph Correspondence Learning</span>
                    <span>Juncheng Li, Junlin Xie, Long Qian, Linchao Zhu, Siliang Tang, Fei Wu, Yi Yang, Yueting Zhuang, Xin Eric Wang</span>
                    <span>
                        <b>CVPR 2022</b>
                    </span>
                    <span>
                    </span>
                </li>

                <li class="li-paper">
                    <span class="title">M3L: Language-based Video Editing via Multi-Modal Multi-Level Transformer</span>
                    <span>Tsu-Jui Fu, Xin Eric Wang, Scott Grafton, Miguel Eckstein, William Yang Wang</span>
                    <span>
                        <b>CVPR 2022</b>
                    </span>
                    <span>
                    </span>
                </li>

                <li class="li-paper">
                    <span class="title">Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions</span>
                    <span>Jing Gu, Eliana Stefani, Qi Wu, Jesse Thomason, Xin Eric Wang</span>
                    <span>
                        <b>ACL 2022</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Assessing Multilingual Fairness in Pretrained Multimodal Representations</span>
                    <span>Jialu Wang, Yang Liu, Xin Eric Wang</span>
                    <span>
                        <b>Findings of ACL 2022</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Interpretable Research Replication Prediction via Variational Contextual Consistency Sentence Masking</span>
                    <span>Tianyi Luo, Rui Meng, Xin Eric Wang, Yang Liu</span>
                    <span>
                        <b>Findings of ACL 2022</b>
                    </span>
                    <span>
                    </span>
                </li>
            <h4>2021</h4>
                <li class="li-paper">
                    <span class="title">Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search</span>
                    <span>Jialu Wang, Yang Liu, Xin Eric Wang</span>
                    <span>
                        <b>EMNLP 2021</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation                    </span>
                    <span>Linjie Li, Jie Lei, Zhe Gan, Licheng Yu, Yen-Chun Chen, Rohit Pillai, Yu Cheng, Luowei Zhou, Xin Eric Wang, <br>
                        William Yang Wang, Tamara Lee Berg, Mohit Bansal, Jingjing Liu, Lijuan Wang, Zicheng Liu</span>
                    <span>
                        <b>NeurIPS 2021</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Visual Question Rewriting for Increasing Response Rate</span>
                    <span>Jiayi Wei, Xilian Li, Yi Zhang, Xin Eric Wang</span>
                    <span>
                        <b>SIGIR 2021</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Multimodal Text Style Transfer for Outdoor Vision-and-Language Navigation                    </span>
                    <span>Wanrong Zhu, Xin Eric Wang, Tsu-Jui Fu, An Yan, Pradyumna Narayana, Kazoo Sone, Sugato Basu, William Yang Wang                    </span>
                    <span>
                        <b>EACL 2021</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">L2C: Describing Visual Differences Needs Semantic Understanding of Individuals                    </span>
                    <span>An Yan, Xin Eric Wang, Tsu-Jui Fu, William Yang Wang                    </span>
                    <span>
                        <b>EACL 2021                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <h4>2020</h4>
                <li class="li-paper">
                    <span class="title">Closing the Loop Between Language and Vision for Embodied Agents</span>
                    <span>Xin Wang</span>
                    <span>
                        <b>UC Santa Barbara                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">SSCR: Iterative Language-Based Image Editing via Self-Supervised Counterfactual Reasoning                    </span>
                    <span>Tsu-Jui Fu, Xin Eric Wang, Scott Grafton, Miguel Eckstein, William Yang Wang</span>
                    <span>
                        <b>EMNLP 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations                    </span>
                    <span>Wanrong Zhu☆, Xin Eric Wang, Pradyumna Narayana, Kazoo Sone, Sugato Basu, William Yang Wang                    </span>
                    <span>
                        <b>EMNLP 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Learning to Stop: A Simple yet Effective Approach to Urban Vision-Language Navigation                    </span>
                    <span>Jiannan Xiang☆, Xin Eric Wang, William Yang Wang                    </span>
                    <span>
                        <b>Findings of EMNLP 2020</b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Environment-agnostic Multitask Learning for Natural Language Grounded Navigation                    </span>
                    <span>Xin Eric Wang*, Vihan Jain*, Eugene Ie, William Yang Wang, Zornitsa Kozareva, Sujith Ravi                    </span>
                    <span>
                        <b>ECCV 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Counterfactual Vision-and-Language Navigation via Adversarial Path Sampling                    </span>
                    <span>Tsu-Jui Fu, Xin Eric Wang, Matthew Peterson, Scott Grafton, Miguel Eckstein, William Yang Wang                    </span>
                    <span>
                        <b>ECCV 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                
                <li class="li-paper">
                    <span class="title">Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation                    </span>
                    <span>Juncheng Li, Xin Wang, Siliang Tang, Haizhou Shi, Fei Wu, Yueting Zhuang, William Yang Wang                    </span>
                    <span>
                        <b>CVPR 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>

                <li class="li-paper">
                    <span class="title">REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments                    </span>
                    <span>Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William Yang Wang, Chunhua Shen, Anton van den Hengel                    </span>
                    <span>
                        <b>CVPR 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Vision-Language Navigation Policy Learning and Adaptation                    </span>
                    <span>Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang, Lei Zhang                    </span>
                    <span>
                        <b>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs                    </span>
                    <span>Pengda Qin, Xin Wang, Wenhu Chen, Chunyun Zhang, Weiran Xu, William Yang Wang                    </span>
                    <span>
                        <b>AAAI 2020                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <h4>2019</h4>
                <li class="li-paper">
                    <span class="title"> </span>
                    <span> </span>
                    <span>
                        <b> </b>
                    </span>
                    <span>
                    </span>
                </li>

                <li class="li-paper">
                    <span class="title">TIGEr: Text-to-Image Grounding for Image Caption Evaluation                    </span>
                    <span>Ming Jiang, Qiuyuan Huang, Lei Zhang, Xin Wang, Pengchuan Zhang, Zhe Gan, Jana Diesner, Jianfeng Gao                    </span>
                    <span>
                        <b>EMNLP-IJCNLP 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">VATEX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research                    </span>
                    <span>Xin Wang*, Jiawei Wu*, Junkun Chen, Lei Li, Yuan-Fang Wang, William Yang Wang                    </span>
                    <span>
                        <b>ICCV 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation                    </span>
                    <span>Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang, Lei Zhang                    </span>
                    <span>
                        <b>CVPR 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment                    </span>
                    <span>Da Zhang, Xiyang Dai, Xin Wang, Yuan-Fang Wang, Larry S. Davis                    </span>
                    <span>
                        <b>CVPR 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Self-Supervised Dialogue Learning                    </span>
                    <span>Jiawei Wu, Xin Wang, William Yang Wang                    </span>
                    <span>
                        <b>ACL 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Self-Supervised Learning for Contextualized Extractive Summarization                    </span>
                    <span>Hong Wang, Xin Wang, Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Shiyu Chang, William Yang Wang                    </span>
                    <span>
                        <b>ACL 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Towards Generating Long and Coherent Text with Multi-Level Latent Variable Models                    </span>
                    <span>Dinghan Shen, Asli Celikyilmaz, Yizhe Zhang, Liqun Chen, Xin Wang, Jianfeng Gao, Lawrence Carin                    </span>
                    <span>
                        <b>ACL 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Extract and Edit: An Alternative to Back-Translation for Unsupervised Neural Machine Translation                    </span>
                    <span>Jiawei Wu, Xin Wang, William Yang Wang                    </span>
                    <span>
                        <b>NAACL 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning                    </span>
                    <span>Xin Wang, Jiawei Wu, Da Zhang, Yu Su, William Yang Wang                    </span>
                    <span>
                        <b>AAAI 2019                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <h4>2018</h4>
                <li class="li-paper">
                    <span class="title">Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation                    </span>
                    <span>Xin Wang*, Wenhan Xiong*, Hongmin Wang, William Yang Wang                    </span>
                    <span>
                        <b>ECCV 2018                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">XL-NBT: A Cross-lingual Neural Belief Tracking Framework                    </span>
                    <span>Wenhu Chen, Jianshu Chen, Yu Su, Xin Wang, Dong Yu, Xifeng Yan, William Yang Wang                    </span>
                    <span>
                        <b>EMNLP 2018                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling                    </span>
                    <span>Xin Wang*, Wenhu Chen*, Yuan-Fang Wang, William Yang Wang                    </span>
                    <span>
                        <b>ACL 2018                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">S3D: Single Shot multi-Span Detector via Fully 3D Convolutional Network                    </span>
                    <span>Da Zhang, Xiyang Dai, Xin Wang, Yuan-Fang Wang                    </span>
                    <span>
                        <b>BMVC 2018                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Video Captioning via Hierarchical Reinforcement Learning                    </span>
                    <span>Xin Wang, Wenhu Chen, Jiawei Wu, Yuan-Fang Wang, William Yang Wang                    </span>
                    <span>
                        <b>CVPR 2018                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning                    </span>
                    <span>Xin Wang, Yuan-Fang Wang, William Yang Wang                    </span>
                    <span>
                        <b>NAACL-HLT 2018                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <h4>2017</h4>
                <li class="li-paper">
                    <span class="title">Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer </span>
                    <span>Xin Wang, Geoffrey Oxholm, Da Zhang, Yuan-Fang Wang                    </span>
                    <span>
                        <b>CVPR 2017                        </b>
                    </span>
                    <span>
                    </span>
                </li>
                <li class="li-paper">
                    <span class="title">Deep Reinforcement Learning for Visual Object Tracking in Videos                    </span>
                    <span>Da Zhang, Hamid Maei, Xin Wang, Yuan-Fang Wang                    </span>
                    <span>
                        <b>Tech report 2017                        </b>
                    </span>
                    <span>
                    </span>
                </li>

            </div>
          </div>




        <br/>

        <hr>

        <div class="container footer">
            <div class="row">
                <div class="col-lg-6 col-md-6 col-sm-6 col-xs-12 thumb">
                    <p>
                        UC Santa Cruz,<br>
                        1156 High Street, <br>
                        Santa Cruz, CA, <br>
                        95064<br>
                    </p>
                </div>
            </div>
        </div>
    </body>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script>window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')</script>
    <script src="static/js/popper.min.js"></script>
    <script src="static/js/bootstrap.min.js"></script>

</html>